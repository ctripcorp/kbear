#producer config bootstrap.servers should point to target cluster
bootstrap.servers=<ip>:9092,<ip>:9092

key.serializer=org.apache.kafka.common.serialization.StringSerializer

value.serializer=org.apache.kafka.common.serialization.ByteArraySerializer
# The total bytes of memory the producer can use to buffer records waiting to be sent to the server.
# If records are sent faster than they can be delivered to the server the producer will either block
# or throw an exception based on the preference specified by block.on.buffer.full
# (134217728 128M) (268435456 256M)
buffer.memory=134217728

# The maximum size of a request. This is also effectively a cap on the maximum record size.
# (104857600 100M) (83886080 80M)
max.request.size=104857600

# The size of the TCP receive buffer to use when reading data
receive.buffer.bytes=2097152

# The size of the TCP send buffer to use when sending data
send.buffer.bytes=2097152

# specify the compression codec for all data generated: none , gzip, snappy.
# the old config values work as well: 0, 1, 2 for none, gzip, snappy, respectivally
compression.type=none

acks=0

retries=0

linger.ms=150

# The configuration controls how long KafkaProducer.send() and KafkaProducer.partitionsFor() will block.
# These methods can be blocked either because the buffer is full or metadata unavailable.Blocking
# in the user-supplied serializers or partitioner will not be counted against this timeout.
max.block.ms=10000

# The configuration controls the maximum amount of time the client will wait for the response of a request.
# If the response is not received before the timeout elapses the client will resend the request
# if necessary or fail the request if retries are exhausted.
request.timeout.ms=30000